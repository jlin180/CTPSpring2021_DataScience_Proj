{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smart-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install glob2\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "certain-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "#import\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import graphviz\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rising-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_images = []\n",
    "labels = [] \n",
    "\n",
    "for fruit_dir_path in glob.glob(\"./fruits-360/Training/*\"):\n",
    "    fruit_label = fruit_dir_path.split(\"/\")[-1] \n",
    "    #fruit_label = fruit_dir_path.split(\"\\\\\")[-1] for windows\n",
    "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        fruit_images.append(image)\n",
    "        labels.append(fruit_label)\n",
    "fruit_images = np.array(fruit_images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\n",
    "id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "desirable-sister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Apple Braeburn',\n",
       " 1: 'Apple Crimson Snow',\n",
       " 2: 'Apple Golden 1',\n",
       " 3: 'Apple Golden 2',\n",
       " 4: 'Apple Golden 3',\n",
       " 5: 'Apple Granny Smith',\n",
       " 6: 'Apple Pink Lady',\n",
       " 7: 'Apple Red 1',\n",
       " 8: 'Apple Red 2',\n",
       " 9: 'Apple Red 3',\n",
       " 10: 'Apple Red Delicious',\n",
       " 11: 'Apple Red Yellow 1',\n",
       " 12: 'Apple Red Yellow 2',\n",
       " 13: 'Apricot',\n",
       " 14: 'Avocado',\n",
       " 15: 'Avocado ripe',\n",
       " 16: 'Banana',\n",
       " 17: 'Banana Lady Finger',\n",
       " 18: 'Banana Red',\n",
       " 19: 'Beetroot',\n",
       " 20: 'Blueberry',\n",
       " 21: 'Cactus fruit',\n",
       " 22: 'Cantaloupe 1',\n",
       " 23: 'Cantaloupe 2',\n",
       " 24: 'Carambula',\n",
       " 25: 'Cauliflower',\n",
       " 26: 'Cherry 1',\n",
       " 27: 'Cherry 2',\n",
       " 28: 'Cherry Rainier',\n",
       " 29: 'Cherry Wax Black',\n",
       " 30: 'Cherry Wax Red',\n",
       " 31: 'Cherry Wax Yellow',\n",
       " 32: 'Chestnut',\n",
       " 33: 'Clementine',\n",
       " 34: 'Cocos',\n",
       " 35: 'Corn',\n",
       " 36: 'Corn Husk',\n",
       " 37: 'Cucumber Ripe',\n",
       " 38: 'Cucumber Ripe 2',\n",
       " 39: 'Dates',\n",
       " 40: 'Eggplant',\n",
       " 41: 'Fig',\n",
       " 42: 'Ginger Root',\n",
       " 43: 'Granadilla',\n",
       " 44: 'Grape Blue',\n",
       " 45: 'Grape Pink',\n",
       " 46: 'Grape White',\n",
       " 47: 'Grape White 2',\n",
       " 48: 'Grape White 3',\n",
       " 49: 'Grape White 4',\n",
       " 50: 'Grapefruit Pink',\n",
       " 51: 'Grapefruit White',\n",
       " 52: 'Guava',\n",
       " 53: 'Hazelnut',\n",
       " 54: 'Huckleberry',\n",
       " 55: 'Kaki',\n",
       " 56: 'Kiwi',\n",
       " 57: 'Kohlrabi',\n",
       " 58: 'Kumquats',\n",
       " 59: 'Lemon',\n",
       " 60: 'Lemon Meyer',\n",
       " 61: 'Limes',\n",
       " 62: 'Lychee',\n",
       " 63: 'Mandarine',\n",
       " 64: 'Mango',\n",
       " 65: 'Mango Red',\n",
       " 66: 'Mangostan',\n",
       " 67: 'Maracuja',\n",
       " 68: 'Melon Piel de Sapo',\n",
       " 69: 'Mulberry',\n",
       " 70: 'Nectarine',\n",
       " 71: 'Nectarine Flat',\n",
       " 72: 'Nut Forest',\n",
       " 73: 'Nut Pecan',\n",
       " 74: 'Onion Red',\n",
       " 75: 'Onion Red Peeled',\n",
       " 76: 'Onion White',\n",
       " 77: 'Orange',\n",
       " 78: 'Papaya',\n",
       " 79: 'Passion Fruit',\n",
       " 80: 'Peach',\n",
       " 81: 'Peach 2',\n",
       " 82: 'Peach Flat',\n",
       " 83: 'Pear',\n",
       " 84: 'Pear 2',\n",
       " 85: 'Pear Abate',\n",
       " 86: 'Pear Forelle',\n",
       " 87: 'Pear Kaiser',\n",
       " 88: 'Pear Monster',\n",
       " 89: 'Pear Red',\n",
       " 90: 'Pear Stone',\n",
       " 91: 'Pear Williams',\n",
       " 92: 'Pepino',\n",
       " 93: 'Pepper Green',\n",
       " 94: 'Pepper Orange',\n",
       " 95: 'Pepper Red',\n",
       " 96: 'Pepper Yellow',\n",
       " 97: 'Physalis',\n",
       " 98: 'Physalis with Husk',\n",
       " 99: 'Pineapple',\n",
       " 100: 'Pineapple Mini',\n",
       " 101: 'Pitahaya Red',\n",
       " 102: 'Plum',\n",
       " 103: 'Plum 2',\n",
       " 104: 'Plum 3',\n",
       " 105: 'Pomegranate',\n",
       " 106: 'Pomelo Sweetie',\n",
       " 107: 'Potato Red',\n",
       " 108: 'Potato Red Washed',\n",
       " 109: 'Potato Sweet',\n",
       " 110: 'Potato White',\n",
       " 111: 'Quince',\n",
       " 112: 'Rambutan',\n",
       " 113: 'Raspberry',\n",
       " 114: 'Redcurrant',\n",
       " 115: 'Salak',\n",
       " 116: 'Strawberry',\n",
       " 117: 'Strawberry Wedge',\n",
       " 118: 'Tamarillo',\n",
       " 119: 'Tangelo',\n",
       " 120: 'Tomato 1',\n",
       " 121: 'Tomato 2',\n",
       " 122: 'Tomato 3',\n",
       " 123: 'Tomato 4',\n",
       " 124: 'Tomato Cherry Red',\n",
       " 125: 'Tomato Heart',\n",
       " 126: 'Tomato Maroon',\n",
       " 127: 'Tomato Yellow',\n",
       " 128: 'Tomato not Ripened',\n",
       " 129: 'Walnut',\n",
       " 130: 'Watermelon'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dirty-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIDs = np.array([label_to_id_dict[x] for x in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-freeze",
   "metadata": {},
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-amount",
   "metadata": {},
   "source": [
    "## PCA \n",
    "- What is PCA\n",
    "- Why are we doing it\n",
    "- How we are doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "traditional-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_scaled = StandardScaler().fit_transform([i.flatten() for i in fruit_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bright-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "pca_result = pca.fit_transform(images_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-process",
   "metadata": {},
   "source": [
    "# Training Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pca_result, labelIDs, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expanded-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "center-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eight-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.54499793180878\n"
     ]
    }
   ],
   "source": [
    "precision = accuracy_score(test_predictions, y_test) * 100\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-compact",
   "metadata": {},
   "source": [
    "### Validating with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "advance-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = []\n",
    "validation_labels = []\n",
    "\n",
    "for fruit_dir_path in glob.glob(\"./fruits-360/Validation/*\"):\n",
    "    fruit_label = fruit_dir_path.split(\"/\")[-1]\n",
    "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        fruit_images.append(image)\n",
    "        labels.append(fruit_label)\n",
    "        \n",
    "validation_images = np.array(validation_images)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "banned-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = np.array([label_to_id_dict[x] for x in validation_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "modular-cocktail",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6b55b0cd8607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_images_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "validation_images_scaled = StandardScaler().transform([i.flatten() for i in validation_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-transport",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
